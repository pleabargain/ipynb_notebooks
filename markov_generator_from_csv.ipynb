{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "markov generator from csv.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pleabargain/ipynb_notebooks/blob/master/markov_generator_from_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "j_IWdyjPre7O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Word Prediction using Markov Model"
      ]
    },
    {
      "metadata": {
        "id": "moJpPYyZre7P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook makes use of Markov model for word prediction. Specifically 2nd order Markov model is deployed here for next word prediction. As an example of the Markov chain, an attempt is made to generate a new song lyrics from a bunch of Eminem song lyrics."
      ]
    },
    {
      "metadata": {
        "id": "oNUytzuVre7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preamble\n",
        "import string\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8FCVbyDre7T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Path of the text file containing the training data\n",
        "training_data_file = 'test.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z3g3GjXqre7W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "pXRQxdw2re7X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ]
    },
    {
      "metadata": {
        "id": "-A_7Ec44re7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def remove_punctuation(sentence):\n",
        "    return sentence.translate(str.maketrans('','', string.punctuation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b9Fsul1Ere7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add2dict(dictionary, key, value):\n",
        "    if key not in dictionary:\n",
        "        dictionary[key] = []\n",
        "    dictionary[key].append(value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01fKah9Lre7d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def list2probabilitydict(given_list):\n",
        "    probability_dict = {}\n",
        "    given_list_length = len(given_list)\n",
        "    for item in given_list:\n",
        "        probability_dict[item] = probability_dict.get(item, 0) + 1\n",
        "    for key, value in probability_dict.items():\n",
        "        probability_dict[key] = value / given_list_length\n",
        "    return probability_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JMTWBb_Jre7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "initial_word = {}\n",
        "second_word = {}\n",
        "transitions = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJrmYJXbre7j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training function"
      ]
    },
    {
      "metadata": {
        "id": "CZMMk2gsre7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Trains a Markov model based on the data in training_data_file\n",
        "def train_markov_model():\n",
        "    for line in open(training_data_file):\n",
        "        tokens = remove_punctuation(line.rstrip().lower()).split()\n",
        "        tokens_length = len(tokens)\n",
        "        for i in range(tokens_length):\n",
        "            token = tokens[i]\n",
        "            if i == 0:\n",
        "                initial_word[token] = initial_word.get(token, 0) + 1\n",
        "            else:\n",
        "                prev_token = tokens[i - 1]\n",
        "                if i == tokens_length - 1:\n",
        "                    add2dict(transitions, (prev_token, token), 'END')\n",
        "                if i == 1:\n",
        "                    add2dict(second_word, prev_token, token)\n",
        "                else:\n",
        "                    prev_prev_token = tokens[i - 2]\n",
        "                    add2dict(transitions, (prev_prev_token, prev_token), token)\n",
        "    \n",
        "    # Normalize the distributions\n",
        "    initial_word_total = sum(initial_word.values())\n",
        "    for key, value in initial_word.items():\n",
        "        initial_word[key] = value / initial_word_total\n",
        "        \n",
        "    for prev_word, next_word_list in second_word.items():\n",
        "        second_word[prev_word] = list2probabilitydict(next_word_list)\n",
        "        \n",
        "    for word_pair, next_word_list in transitions.items():\n",
        "        transitions[word_pair] = list2probabilitydict(next_word_list)\n",
        "    \n",
        "    print('Training successful.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oNSteH1Tre7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bdb8da5-f7a6-4673-e8e1-0e9cb40b1482"
      },
      "cell_type": "code",
      "source": [
        "train_markov_model()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training successful.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "51XZvI2pre7q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://)## Testing"
      ]
    },
    {
      "metadata": {
        "id": "ktDDyn5rre7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ]
    },
    {
      "metadata": {
        "id": "axM4eF73re7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample_word(dictionary):\n",
        "    p0 = np.random.random()\n",
        "    cumulative = 0\n",
        "    for key, value in dictionary.items():\n",
        "        cumulative += value\n",
        "        if p0 < cumulative:\n",
        "            return key\n",
        "    assert(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XnpeMnhhre7v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test functions"
      ]
    },
    {
      "metadata": {
        "id": "mCmBWx_dre7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "number_of_sentences = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pMoqnI_Wre7z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to generate sample text\n",
        "def generate():\n",
        "    for i in range(number_of_sentences):\n",
        "        sentence = []\n",
        "        # Initial word\n",
        "        word0 = sample_word(initial_word)\n",
        "        sentence.append(word0)\n",
        "        # Second word\n",
        "        word1 = sample_word(second_word[word0])\n",
        "        sentence.append(word1)\n",
        "        # Subsequent words untill END\n",
        "        while True:\n",
        "            word2 = sample_word(transitions[(word0, word1)])\n",
        "            if word2 == 'END':\n",
        "                break\n",
        "            sentence.append(word2)\n",
        "            word0 = word1\n",
        "            word1 = word2\n",
        "        print(' '.join(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bd-_69Were71",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Testing arena"
      ]
    },
    {
      "metadata": {
        "id": "eXAyMUd7re72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "20e86600-a484-49e5-9c65-7d64b812a29d"
      },
      "cell_type": "code",
      "source": [
        "generate()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "basically boy youre never gonna be capable\n",
            "i cannot grow old in salems lot\n",
            "and guess who just happens to be overseas\n",
            "syllables skillaholic kill em all in a time warp from two thousand four though\n",
            "let me know when it occurs to you\n",
            "the clocks run out times up over blaow\n",
            "enough rhymes to\n",
            "all my sins need holy water feel it washing over me\n",
            "but i dont know how to make songs like that one line i said\n",
            "and i am not then ima stop pinning em\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}